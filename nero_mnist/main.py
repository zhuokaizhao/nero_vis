from __future__ import print_function
import os
import sys
import time
import torch
import e2cnn
import argparse
import numpy as np
import torchvision
import torch.optim as optim
from subprocess import call
import torch.nn.functional as F
import matplotlib.pyplot as plt
import plotly.graph_objects as go
from torch.optim.lr_scheduler import StepLR

from PIL import Image


import vis
import models
import datasets

os.environ['CUDA_VISIBLE_DEVICES']='0'

# print cuda information
print('\n\nPython VERSION:', sys.version)
print('PyTorch VERSION:', torch.__version__)
print('CUDNN VERSION:', torch.backends.cudnn.version())
print('Number CUDA Devices:', torch.cuda.device_count())
print('Devices')
call(['nvidia-smi', '--format=csv', '--query-gpu=index,name,driver_version,memory.total,memory.used,memory.free'])
print('Active CUDA Device: GPU', torch.cuda.current_device())

print ('Available devices ', torch.cuda.device_count())
print ('Current cuda device ', torch.cuda.current_device())

# Print iterations progress
def print_progress_bar (iteration, total, prefix = '', suffix = '', decimals = 1, length = 100, fill = 'â–ˆ', printEnd = "\r"):
    """
    Call in a loop to create terminal progress bar
    @params:
        iteration   - Required  : current iteration (Int)
        total       - Required  : total iterations (Int)
        prefix      - Optional  : prefix string (Str)
        suffix      - Optional  : suffix string (Str)
        decimals    - Optional  : positive number of decimals in percent complete (Int)
        length      - Optional  : character length of bar (Int)
        fill        - Optional  : bar fill character (Str)
        printEnd    - Optional  : end character (e.g. "\r", "\r\n") (Str)
    """
    percent = ("{0:." + str(decimals) + "f}").format(100 * (iteration / float(total)))
    filledLength = int(length * iteration // total)
    bar = fill * filledLength + '-' * (length - filledLength)
    print('\r%s |%s| %s%% %s' % (prefix, bar, percent, suffix), end = printEnd)
    # Print New Line on Complete
    if iteration == total:
        print()


# train each epoch
def train(model, device, train_loader, optimizer):
    all_batch_losses = []
    model.train()
    loss_function = torch.nn.CrossEntropyLoss()
    for batch_idx, (data, target) in enumerate(train_loader):
        batch_time_start = time.time()
        # move data to GPU
        data, target = data.to(device), target.to(device)
        optimizer.zero_grad()
        output = model(data)
        # negative log likelihood loss.
        loss = loss_function(output, target)
        loss.backward()
        all_batch_losses.append(loss.item())
        optimizer.step()
        batch_time_end = time.time()
        batch_time_cost = batch_time_end - batch_time_start

        print_progress_bar(iteration=batch_idx+1,
                            total=len(train_loader),
                            prefix=f'Train batch {batch_idx+1}/{len(train_loader)},',
                            suffix='%s: %.3f, time: %.2f' % ('CE loss', all_batch_losses[-1], batch_time_cost),
                            length=50)

    # return the averaged batch loss
    return np.mean(all_batch_losses)


# validation
def val(model, device, val_loader):
    model.eval()
    loss_function = torch.nn.CrossEntropyLoss()
    all_batch_losses = []
    num_correct = 0
    with torch.no_grad():
        for batch_idx, (data, target) in enumerate(val_loader):
            batch_time_start = time.time()
            data, target = data.to(device), target.to(device)
            output = model(data)
            loss = loss_function(output, target)
            all_batch_losses.append(loss.item())
            # get the index of the max log-probability
            pred = output.argmax(dim=1, keepdim=True)
            num_correct += pred.eq(target.view_as(pred)).sum().item()
            batch_time_end = time.time()
            batch_time_cost = batch_time_end - batch_time_start

            print_progress_bar(iteration=batch_idx+1,
                                total=len(val_loader),
                                prefix=f'Val batch {batch_idx+1}/{len(val_loader)},',
                                suffix='%s: %.3f, time: %.2f' % ('CE loss', all_batch_losses[-1], batch_time_cost),
                                length=50)

    # return the averaged batch loss
    return np.mean(all_batch_losses), num_correct


# test
def test(model, device, test_loader):
    model.eval()
    loss_function = torch.nn.CrossEntropyLoss(reduction='none')
    general_batch_losses = []
    general_num_correct = 0
    # categorical number of correct
    categorical_num_digits = np.zeros(10, dtype=int)
    categorical_num_correct = np.zeros(10, dtype=int)
    # categorical loss
    categorical_losses = np.zeros(10)

    with torch.no_grad():
        for batch_idx, (data, target) in enumerate(test_loader):
            batch_time_start = time.time()
            # print(target)
            # prepare current batch's testing data
            data, target = data.to(device), target.to(device)

            # inference
            output = model(data)
            loss = loss_function(output, target)
            general_batch_losses.append(torch.mean(loss).item())

            # get the index of the max log-probability
            pred = output.argmax(dim=1, keepdim=True)
            general_num_correct += pred.eq(target.view_as(pred)).sum().item()

            # calculate per-class performance
            # total number of cases for each class (digit)
            for i in range(10):
                categorical_num_digits[i] += int(target.cpu().tolist().count(i))

            # number of correct for each case
            for i in range(len(pred)):
                # losses
                categorical_losses[target.cpu().tolist()[i]] += loss[i]
                # correctness
                if pred.eq(target.view_as(pred))[i].item() == True:
                    categorical_num_correct[target.cpu().tolist()[i]] += 1

            batch_time_end = time.time()
            batch_time_cost = batch_time_end - batch_time_start

            print_progress_bar(iteration=batch_idx+1,
                                total=len(test_loader),
                                prefix=f'Test batch {batch_idx+1}/{len(test_loader)},',
                                suffix='%s: %.3f, time: %.2f' % ('CE loss', general_batch_losses[-1], batch_time_cost),
                                length=50)

    general_loss = np.mean(general_batch_losses)
    general_accuracy = general_num_correct / len(test_loader.dataset)
    categorical_loss = categorical_losses / categorical_num_digits
    categorical_accuracy = categorical_num_correct / categorical_num_digits

    # return the averaged batch loss
    return general_loss, general_accuracy, categorical_loss, categorical_accuracy


def main():
    # Training settings
    parser = argparse.ArgumentParser(description='NERO plots with MNIST')
    # mode (train, test_rot_eqv, test_trans_eqv or analyze)
    parser.add_argument('--mode', required=True, action='store', nargs=1, dest='mode')
    # network method (non-eqv, eqv, etc)
    parser.add_argument('-n', '--network_model', action='store', nargs=1, dest='network_model')
    # dataset
    # parser.add_argument('-d', '--data-name', action='store', nargs=1, dest='data_name')
    # image dimension after padding
    parser.add_argument('-s', '--image_size', action='store', nargs=1, dest='image_size')
    # training batch size
    parser.add_argument('--train_batch_size', type=int, dest='train_batch_size',
                        help='input batch size for training')
    # validation batch size
    parser.add_argument('--val_batch_size', type=int, dest='val_batch_size',
                        help='input batch size for validation')
    # test batch size
    parser.add_argument('--test_batch_size', type=int, dest='test_batch_size',
                        help='input batch size for testing')
    # number of training epochs
    parser.add_argument('-e', '--num_epoch', type=int, dest='num_epoch',
                        help='number of epochs to train')
    # save the checkpoint model to the output model directory
    parser.add_argument("--checkpoint_interval", type=int, default=5, help="interval between saving model weights")
    # checkpoint path for continuing training
    parser.add_argument('-c', '--checkpoint_dir', action='store', nargs=1, dest='checkpoint_path')
    # input or output model directory
    parser.add_argument('-m', '--model_dir', action='store', nargs=1, dest='model_dir')
    # output figs directory
    parser.add_argument('-o', '--output_dir', action='store', nargs=1, dest='output_dir')
    # verbosity
    parser.add_argument('-v', '--verbose', action='store_true', dest='verbose', default=False)

    args = parser.parse_args()

    # input variables
    mode = args.mode[0]
    if args.image_size != None:
        image_size = (int(args.image_size[0].split('x')[0]), int(args.image_size[0].split('x')[1]))
    else:
        image_size = None
    # output graph directory
    figs_dir = args.output_dir[0]
    verbose = args.verbose

    # training mode
    if mode == 'train':
        network_model = args.network_model[0]
        # default train_batch_size and val_batch_size if not assigned
        if args.train_batch_size == None:
            train_batch_size = 64
            val_batch_size = 1000
        else:
            train_batch_size = args.train_batch_size
            val_batch_size = args.val_batch_size

        # number of training epoch
        num_epoch = args.num_epoch

        # number of groups for e2cnn
        if network_model == 'rot-eqv':
            num_rotation = 8

        # MNIST models use Adam
        learning_rate = 5e-5
        weight_decay = 1e-5

        # checkpoint path to load the model from
        if args.checkpoint_path != None:
            checkpoint_path = args.checkpoint_path[0]
        else:
            checkpoint_path = None

        # directory to save the model to
        model_dir = args.model_dir[0]

        # kwargs for train and val dataloader
        train_kwargs = {'batch_size': train_batch_size}
        val_kwargs = {'batch_size': val_batch_size}
        if torch.cuda.is_available():
            # additional cuda kwargs
            cuda_kwargs = {'num_workers': 8,
                            'pin_memory': True,
                            'shuffle': True}
            train_kwargs.update(cuda_kwargs)
            val_kwargs.update(cuda_kwargs)

            # device set up
            if torch.cuda.device_count() > 1:
                print('\n', torch.cuda.device_count(), 'GPUs available')
                device = torch.device('cuda')
            else:
                device = torch.device('cuda:0')
        else:
            device = torch.device('cpu')

        if verbose:
            print(f'\nmode: {mode}')
            print(f'GPU usage: {device}')
            print(f'netowrk model: {network_model}')
            if image_size != None:
                print(f'Padded image size: {image_size[0]}x{image_size[1]}')
            else:
                print(f'Padded image size: {image_size}')
            print(f'training batch size: {train_batch_size}')
            print(f'validation batch size: {val_batch_size}')
            print(f'output model dir: {model_dir}')
            print(f'epoch size: {num_epoch}')
            print(f'initial learning rate: {learning_rate}')
            print(f'optimizer weight decay: {weight_decay}')
            print(f'model input checkpoint path: {checkpoint_path}')

        # transform
        if image_size != None:
            transform = torchvision.transforms.Compose([
                # transform includes padding (right and bottom) to image_size and totensor
                torchvision.transforms.Pad((0, 0, image_size[1]-28, image_size[0]-28), fill=0, padding_mode='constant'),
            ])
        else:
            transform = torchvision.transforms.Compose([
                # transform includes padding (right and bottom) to 29x29 (for model purpose) and totensor
                torchvision.transforms.Pad((0, 0, 1, 1), fill=0, padding_mode='constant'),
            ])
            image_size = (29, 29)

        # split into train and validation dataset
        dataset = datasets.MnistDataset(mode='train', transform=transform)
        train_data, val_data = torch.utils.data.random_split(dataset, [50000, 10000])

        # pytorch data loader
        train_loader = torch.utils.data.DataLoader(train_data, **train_kwargs)
        val_loader = torch.utils.data.DataLoader(val_data, **val_kwargs)

        # model
        starting_epoch = 0
        if network_model == 'non-eqv':
            model = models.Non_Eqv_Net_MNIST().to(device)
            # from pytorch_model_summary import summary
            # print(summary(model, torch.zeros((1, 1, 29, 29)).to(device)))
            # exit()

        elif network_model == 'rot-eqv':
            model = models.Rot_Eqv_Net_MNIST(image_size=image_size, num_rotation=num_rotation).to(device)

        elif network_model == 'trans-eqv':
            model = models.Trans_Eqv_Net_MNIST().to(device)

        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)

        # load previously trained model information
        if checkpoint_path != None:
            checkpoint = torch.load(checkpoint_path)
            model.load_state_dict(checkpoint['state_dict'])
            starting_epoch = checkpoint['epoch']
            optimizer.load_state_dict(checkpoint['optimizer'])

        # train the model
        all_epoch_train_losses = []
        all_epoch_val_losses = []
        for epoch in range(starting_epoch, starting_epoch+num_epoch):
            print(f'\n Starting epoch {epoch+1}/{starting_epoch+num_epoch}')
            epoch_start_time = time.time()
            cur_epoch_train_loss = train(model, device, train_loader, optimizer)
            all_epoch_train_losses.append(cur_epoch_train_loss)
            cur_epoch_val_loss, num_correct = val(model, device, val_loader)
            all_epoch_val_losses.append(cur_epoch_val_loss)
            epoch_end_time = time.time()
            epoch_time_cost = epoch_end_time - epoch_start_time

            print('\nValidation set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\n'.format(
                    cur_epoch_val_loss, num_correct, len(val_loader.dataset),
                    100. * num_correct / len(val_loader.dataset)))

            if (epoch+1) % args.checkpoint_interval == 0:

                # save model as a checkpoint so further training could be resumed
                if network_model == 'non-eqv':
                    model_path = os.path.join(model_dir, f'{network_model}_mnist_{image_size[0]}x{image_size[1]}_batch{train_batch_size}_epoch{epoch+1}.pt')
                elif network_model == 'trans-eqv':
                    model_path = os.path.join(model_dir, f'{network_model}_mnist_{image_size[0]}x{image_size[1]}_batch{train_batch_size}_epoch{epoch+1}.pt')
                elif network_model == 'rot-eqv':
                    model_path = os.path.join(model_dir, f'{network_model}_rot-group{num_rotation}_mnist_{image_size[0]}x{image_size[1]}_batch{train_batch_size}_epoch{epoch+1}.pt')
                else:
                    raise Exception(f'Unknown network model {network_model}')

                # if trained on multiple GPU's, store model.module.state_dict()
                if torch.cuda.device_count() > 1:
                    model_checkpoint = {
                                            'epoch': epoch+1,
                                            'state_dict': model.module.state_dict(),
                                            'optimizer': optimizer.state_dict(),
                                            'train_loss': all_epoch_train_losses,
                                            'val_loss': all_epoch_val_losses
                                        }
                else:
                    model_checkpoint = {
                                            'epoch': epoch+1,
                                            'state_dict': model.state_dict(),
                                            'optimizer': optimizer.state_dict(),
                                            'train_loss': all_epoch_train_losses,
                                            'val_loss': all_epoch_val_losses
                                        }

                torch.save(model_checkpoint, model_path)
                print(f'\nTrained model checkpoint has been saved to {model_path}\n')

                # save loss graph and model
                if checkpoint_path != None:
                    checkpoint = torch.load(checkpoint_path)
                    prev_train_losses = checkpoint['train_loss']
                    prev_val_losses = checkpoint['val_loss']
                    all_epoch_train_losses = prev_train_losses + all_epoch_train_losses
                    all_epoch_val_losses = prev_val_losses + all_epoch_val_losses

                plt.plot(all_epoch_train_losses, label='Train')
                plt.plot(all_epoch_val_losses, label='Validation')
                plt.title(f'Training and validation loss on {network_model} model')
                plt.xlabel('Epoch')
                plt.ylabel('Loss')
                plt.legend(loc='upper right')
                loss_path = os.path.join(figs_dir, f'{network_model}_mnist_batch{train_batch_size}_epoch{epoch+1}_loss.png')
                plt.savefig(loss_path)
                print(f'\nLoss graph has been saved to {loss_path}')


    elif 'test' in mode:

        if args.test_batch_size == None:
            test_batch_size = 1000
        else:
            test_batch_size = args.test_batch_size

        network_model = args.network_model[0]
        # directory to load the model from
        model_dir = args.model_dir[0]
        test_kwargs = {'batch_size': test_batch_size}

        # number of groups for e2cnn
        if network_model == 'rot-eqv':
            num_rotation = 8

        # basic settings for pytorch
        if torch.cuda.is_available():
            # additional kwargs
            cuda_kwargs = {'num_workers': 8,
                            'pin_memory': True,
                            'shuffle': True}
            test_kwargs.update(cuda_kwargs)

            # device set up
            if torch.cuda.device_count() > 1:
                print('\n', torch.cuda.device_count(), 'GPUs available')
                device = torch.device('cuda')
            else:
                device = torch.device('cuda:0')
        else:
            device = torch.device('cpu')

        # model
        if network_model == 'non-eqv':
            model = models.Non_Eqv_Net_MNIST().to(device)

        elif network_model == 'rot-eqv':
            model = models.Rot_Eqv_Net_MNIST(image_size=image_size, num_rotation=num_rotation).to(device)

        elif network_model == 'trans-eqv':
            model = models.Trans_Eqv_Net_MNIST().to(device)

        # load previously trained model
        trained_model = torch.load(model_dir)
        model.load_state_dict(trained_model['state_dict'])
        trained_epoch = trained_model['epoch']

        if verbose:
            print(f'\nmode: {mode}')
            print(f'GPU usage: {device}')
            print(f'netowrk model: {network_model}')
            print(f'testing batch size: {test_batch_size}')
            print(f'input model dir: {model_dir}')

        if image_size == None:
            image_size = (29, 29)

        # test on each rotation degree
        if mode == 'test_rot_eqv':
            max_rot = 360
            increment = 1
            general_loss_heatmap = np.zeros(max_rot//increment)
            general_accuracy_heatmap = np.zeros(max_rot//increment)
            categorical_loss_heatmap = np.zeros((max_rot//increment, 10))
            categorical_accuracy_heatmap = np.zeros((max_rot//increment, 10))

            for k in range(0, max_rot, increment):
                print(f'\n Testing rotation angle {k}/{max_rot-increment}')
                # row
                transform = torchvision.transforms.Compose([
                    # transform includes upsample, rotate, downsample and padding (right and bottom) to image_size
                    torchvision.transforms.Resize(28*3),
                    torchvision.transforms.RandomRotation((k, k), resample=Image.BILINEAR, expand=False),
                    torchvision.transforms.Resize(28),
                    # torchvision.transforms.Pad((i, i, image_size[1]-28-i, image_size[0]-28-i), fill=0, padding_mode='constant'),
                    torchvision.transforms.Pad((0, 0, 1, 1), fill=0, padding_mode='constant'),
                ])

                # prepare test dataset
                dataset = datasets.MnistDataset(mode='test', transform=transform)
                test_loader = torch.utils.data.DataLoader(dataset, **test_kwargs)

                # test the model
                general_loss, general_accuracy, categorical_loss, categorical_accuracy = test(model, device, test_loader)
                general_loss_heatmap[k//increment] = general_loss
                general_accuracy_heatmap[k//increment] = general_accuracy
                categorical_loss_heatmap[k//increment, :] = categorical_loss
                categorical_accuracy_heatmap[k//increment, :] = categorical_accuracy

                print(f'Rotation {k} accuracy: {general_accuracy}')

            # save the accuracy as npz file
            if network_model == 'non-eqv':
                loss_path = os.path.join(figs_dir, f'{network_model}_mnist_{image_size[0]}x{image_size[1]}_angle-increment{increment}_epoch{trained_epoch}_result.npz')
            elif network_model == 'trans-eqv':
                loss_path = os.path.join(figs_dir, f'{network_model}_mnist_{image_size[0]}x{image_size[1]}_angle-increment{increment}_epoch{trained_epoch}_result.npz')
            elif network_model == 'rot-eqv':
                loss_path = os.path.join(figs_dir, f'{network_model}_rot-group{num_rotation}_mnist_{image_size[0]}x{image_size[1]}_angle-increment{increment}_epoch{trained_epoch}_result.npz')
            elif network_model == 'trans-rot-eqv':
                loss_path = os.path.join(figs_dir, f'{network_model}_rot-group{num_rotation}_mnist_{image_size[0]}x{image_size[1]}_angle-increment{increment}_epoch{trained_epoch}_result.npz')

            np.savez(loss_path,
                    general_loss_heatmap=general_loss_heatmap,
                    general_accuracy_heatmap=general_accuracy_heatmap,
                    categorical_loss_heatmap=categorical_loss_heatmap,
                    categorical_accuracy_heatmap=categorical_accuracy_heatmap)

            print(f'\nTesting result has been saved to {loss_path}')

        # plot error at each moved position as a heatmap
        elif mode == 'test_trans_eqv':
            # suppose the padding size is 64x64, mnist has 28x28 images
            num_move = image_size[0] - 28


    elif mode == 'analyze':
        if verbose:
            print(f'\nmode: {mode}')
            print(f'dataset: {data_name}')
            print(f'output figures dir: {figs_dir}')

        # load the non-eqv result
        non_eqv_dir = '/home/zhuokai/Desktop/UChicago/Research/Visualizing-equivariant-properties/classification/mnist/figs/non_eqv'
        non_eqv_name = 'non-eqv_mnist_29x29_angle-increment1_epoch50_result.npz'
        non_eqv_path = os.path.join(non_eqv_dir, non_eqv_name)
        non_eqv_result = np.load(non_eqv_path)

        # load the trans-eqv result
        # trans_eqv_dir = '/home/zhuokai/Desktop/UChicago/Research/Visualizing-equivariant-properties/classification/mnist/figs/trans_eqv'
        # trans_eqv_name = 'trans-eqv_mnist_64x64_angle-increment1_epoch50_result.npz'
        # trans_eqv_path = os.path.join(trans_eqv_dir, trans_eqv_name)
        # trans_eqv_result = np.load(trans_eqv_path)

        # load the rot-eqv result
        rot_eqv_dir = '/home/zhuokai/Desktop/UChicago/Research/Visualizing-equivariant-properties/classification/mnist/figs/rot_eqv'
        rot_eqv_name = 'rot-eqv_rot-group8_mnist_29x29_angle-increment1_epoch30_result.npz'
        rot_eqv_path = os.path.join(rot_eqv_dir, rot_eqv_name)
        rot_eqv_result = np.load(rot_eqv_path)


        # test for each individual digit
        for i in range(10):
            plot_title = f'Non-equivariant vs Equivariant model on {data_name} Digit {i}'
            result_path = os.path.join(figs_dir, f'{data_name}_test_digit_{i}.html')

            # vis.plot_interactive_polar_heatmap(data_name, non_eqv_result, trans_eqv_result, rot_eqv_result, plot_title, result_path)
            vis.plot_interactive_line_polar(i, non_eqv_result, rot_eqv_result, plot_title, result_path)



if __name__ == '__main__':
    main()